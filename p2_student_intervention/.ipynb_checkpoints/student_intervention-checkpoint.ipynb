{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习工程师纳米学位\n",
    "## 监督学习\n",
    "## 项目 2: 搭建一个学生干预系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欢迎来到机器学习工程师纳米学位的第二个项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以**'练习'**开始的标题表示接下来的代码部分中有你必须要实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以**'TODO'**标出。请仔细阅读所有的提示！\n",
    "\n",
    "除了实现代码外，你还**必须**回答一些与项目和你的实现有关的问题。每一个需要你回答的问题都会以**'问题 X'**为标题。请仔细阅读每个问题，并且在问题后的**'回答'**文字框中写出完整的答案。我们将根据你对问题的回答和撰写代码所实现的功能来对你提交的项目进行评分。\n",
    "\n",
    ">**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 1 - 分类 vs. 回归\n",
    "*在这个项目中你的任务是找出那些如果不给予帮助，最终可能无法毕业的学生。你觉得这个问题是哪种类型的监督学习问题，是分类问题还是回归问题？为什么？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**答案: **\n",
    "\n",
    "这是一个分类问题。因为学生能否毕业不是连续的量，是离散的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析数据\n",
    "运行下面区域的代码以载入学生数据集，以及一些此项目所需的Python库。注意数据集的最后一列`'passed'`是我们的预测的目标（表示学生是毕业了还是没有毕业），其他的列是每个学生的属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# 载入所需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 载入学生数据集\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习: 分析数据\n",
    "我们首先通过调查数据，以确定有多少学生的信息，并了解这些学生的毕业率。在下面的代码单元中，你需要完成如下的运算：\n",
    "- 学生的总数， `n_students`。\n",
    "- 每个学生的特征总数， `n_features`。\n",
    "- 毕业的学生的数量， `n_passed`。\n",
    "- 未毕业的学生的数量， `n_failed`。\n",
    "- 班级的毕业率， `grad_rate`， 用百分数表示(%)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of features: 30\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO： 计算学生的数量\n",
    "n_students = student_data.index.size\n",
    "\n",
    "# TODO： 计算特征数量\n",
    "n_features = student_data.columns.size - 1\n",
    "\n",
    "# TODO： 计算通过的学生数\n",
    "n_passed = (student_data['passed'] == 'yes').sum()\n",
    "\n",
    "# TODO： 计算未通过的学生数\n",
    "n_failed = (student_data['passed'] == 'no').sum()\n",
    "\n",
    "# TODO： 计算通过率\n",
    "grad_rate = float(n_passed) * 100 / n_students\n",
    "\n",
    "# 输出结果\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "在这个部分中，我们将要为建模、训练和测试准备数据\n",
    "### 识别特征和目标列\n",
    "你获取的数据中通常都会包含一些非数字的特征，这会导致一些问题，因为大多数的机器学习算法都会期望输入数字特征进行计算。\n",
    "\n",
    "运行下面的代码单元将学生数据分成特征和目标列看一看他们中是否有非数字特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Target column: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# 提取特征列\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# 提取目标列 ‘passed’\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# 显示列的列表\n",
    "print \"Feature columns:\\n{}\".format(feature_cols)\n",
    "print \"\\nTarget column: {}\".format(target_col)\n",
    "\n",
    "# 将数据分割成特征数据和目标数据（即X_all 和 y_all）\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# 通过打印前5行显示特征信息\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.696203</td>\n",
       "      <td>2.749367</td>\n",
       "      <td>2.521519</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.944304</td>\n",
       "      <td>3.235443</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>1.481013</td>\n",
       "      <td>2.291139</td>\n",
       "      <td>3.554430</td>\n",
       "      <td>5.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>1.088201</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.890741</td>\n",
       "      <td>1.287897</td>\n",
       "      <td>1.390303</td>\n",
       "      <td>8.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean    16.696203    2.749367    2.521519    1.448101    2.035443    0.334177   \n",
       "std      1.276043    1.094735    1.088201    0.697505    0.839240    0.743651   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    3.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     3.944304    3.235443    3.108861    1.481013    2.291139    3.554430   \n",
       "std      0.896659    0.998862    1.113278    0.890741    1.287897    1.390303   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    3.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences  \n",
       "count  395.000000  \n",
       "mean     5.708861  \n",
       "std      8.003096  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      4.000000  \n",
       "75%      8.000000  \n",
       "max     75.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理特征列\n",
    "\n",
    "正如你所见，我们这里有几个非数值的列需要做一定的转换！它们中很多是简单的`yes`/`no`，比如`internet`。这些可以合理地转化为`1`/`0`（二元值，binary）值。\n",
    "\n",
    "其他的列，如`Mjob`和`Fjob`，有两个以上的值，被称为_分类变量（categorical variables）_。处理这样的列的推荐方法是创建和可能值一样多的列（如：`Fjob_teacher`，`Fjob_other`，`Fjob_services`等），然后将其中一个的值设为`1`另外的设为`0`。\n",
    "\n",
    "这些创建的列有时候叫做 _虚拟变量（dummy variables）_，我们将用[`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)函数来完成这个转换。运行下面代码单元的代码来完成这里讨论的预处理步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' 预处理学生数据，将非数字的二元特征转化成二元值（0或1），将分类的变量转换成虚拟变量\n",
    "    '''\n",
    "    \n",
    "    # 初始化一个用于输出的DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # 查看数据的每一个特征列\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # 如果数据是非数字类型，将所有的yes/no替换成1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # 如果数据类型是类别的（categorical），将它转换成虚拟变量\n",
    "        if col_data.dtype == object:\n",
    "            # 例子: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # 收集转换后的列\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现: 将数据分成训练集和测试集\n",
    "现在我们已经将所有的 _分类的（categorical）_ 特征转换成数值了。下一步我们将把数据（包括特征和对应的标签数据）分割成训练集和测试集。在下面的代码单元中，你需要完成下列功能：\n",
    "- 随机混洗（shuffle）切分数据(`X_all`, `y_all`) 为训练子集和测试子集。\n",
    "  - 使用300个数据点作为训练集（约75%），使用95个数据点作为测试集（约25%）。\n",
    "  - 如果可能的话，为你使用的函数设置一个`random_state`。\n",
    "  - 将结果存储在`X_train`, `X_test`, `y_train`和 `y_test`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 300 samples.\n",
      "Testing set has 95 samples.\n"
     ]
    }
   ],
   "source": [
    "# TODO：在这里导入你可能需要使用的另外的功能\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# TODO：设置训练集的数量\n",
    "num_train = 300\n",
    "\n",
    "# TODO：设置测试集的数量\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO：把数据集混洗和分割成上面定义的训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.24, random_state=50)\n",
    "\n",
    "\n",
    "# 显示分割的结果\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和评价模型\n",
    "在这个部分，你将选择3个适合这个问题并且在`scikit-learn`中已有的监督学习的模型。首先你需要说明你选择这三个模型的原因，包括这些数据集有哪些特点，每个模型的优点和缺点各是什么。然后，你需要将这些模型用不同大小的训练集（100个数据点，200个数据点，300个数据点）进行训练，并用F<sub>1</sub>的值来衡量。你需要制作三个表，每个表要显示训练集大小，训练时间，预测时间，训练集上的F<sub>1</sub>值和测试集上的F<sub>1</sub>值（每个模型一个表）。\n",
    "\n",
    "**这是目前** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **里有的监督学习模型，你可以从中选择:**\n",
    "- Gaussian Naive Bayes (GaussianNB) 朴素贝叶斯\n",
    "- Decision Trees 决策树\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent (SGDC)\n",
    "- Support Vector Machines (SVM) 向量模型机\n",
    "- Logistic Regression 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 2 - 应用模型\n",
    "*列出三个适合这个问题的监督学习算法模型。每一个你选择的模型：*\n",
    "\n",
    "- 描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）\n",
    "- 这个模型的优势是什么？他什么情况下表现最好？\n",
    "- 这个模型的缺点是什么？什么条件下它表现很差？\n",
    "- 根据我们当前数据集的特点，为什么这个模型适合这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **\n",
    "\n",
    "我认为三个适合这个问题的算法模型是：Decision Trees， K-Nearest Neighbors ， Support Vector Machines 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees\n",
    "- 应用场景\n",
    "\n",
    "决策树尤其适合于特征数量有限且较少的情况。所以适合于银行的信用卡邀请系统。\n",
    "\n",
    "银行往往希望发出更多的信用卡，但是又必须对信用卡的持有人进行分类，对于信用良好具备还款能力的人发出邀请。对这类人的判断条件是非常简单的。\n",
    "首先判断这个人的身份是学生还是工作还是无业，其次对学生判断其年龄和成绩，对于工作的人判断其收入即可。决策树如下图：\n",
    "![Mou icon](DecisionTree_Creditcard.png)\n",
    "*出处：http://booksite.elsevier.com/9780124438804/leondes_expert_vol1_ch3.pdf Page57－60*\n",
    "- 优势：决策树的优点在于其算法简单，易于使用，决策树的图形结构清晰能够很好的表示数据，适用于特征有限且较少的情况。\n",
    "- 缺点：对于有大量特征的数据，会生成很复杂的决策树，容易出现过拟合，需要通过调整比较参数来解决这种问题，有时并不能得到很好的效果。\n",
    "- 对于学生干预系统的数据集，虽然它的特征不像信用卡的申请那么简单，但是也并不多，并且可以通过调整max_depth,min_samples_split来改善结果，所以我认为是可以使用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  K-Nearest Neighbors\n",
    "- 应用场景\n",
    "\n",
    "KNN是基于实例的学习,可以用来进行手写数字识别。在识别手写数字的算法中，首先要将手写数字的图片分为训练集和测试集，然后将这些图片都转化为向量。\n",
    "然后计算测试样本与训练样本中各个图片的距离，对距离排序，选距离最近的k个。因为这k个样本来自训练集，我们能够知道来自训练集的样本代表的数字，所以测试样本所代表的数字就是这k个中出现次数最多的那个数字。\n",
    "\n",
    "*出处：* https://wizardforcel.gitbooks.io/dm-algo-top10/content/knn.html\n",
    "- 优势：算法简易，精度高、对异常值不敏感，不需要事先训练。KNN比较适用于多分类问题，比如手写数字，就需要把单个的数字分为10种。\n",
    "- 缺点：KNN因为计算量相当的大，所以相当的耗时，对于数据量很大的数据集效率低。\n",
    "- 对于学生干预系统的数据集，这也是一个分类问题，需要把学生划分为能够顺利毕业和可能不能顺利毕业两种，虽然不能确定KNN算法的最终效果是不是最好的，但是一定是可以使用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Support Vector Machines\n",
    "- 应用场景\n",
    "SVM同样可以用来识别手写数字，但是和KNN使用方法不同。\n",
    "对于已进行过预处理的待识别手写阿拉伯数字图像，先提取穿越次数特征，进行基本分类；再提取粗网格特征以及密度特征，形成一个多维向量，然后用SVM进行数字的分类识别。将每个字符对应的训练样本输入到SVM分类器中，提取特征，形成向量，进行训练。训练完成后,将待识别图像输入,提取特征后，形成向量并分类。\n",
    "\n",
    "*出处：* 文章编号：1009-8119（2005）09-0041-03 基于SVM的手写体阿拉伯数字识别 作者：张鸽，陈书开 （长沙理工大学计算机与通讯工程学院,长沙  410076）\n",
    "- 优势：SVM非常适合用来分类，能够有效地处理高维空间数据，所以我们可以用SVM来分类高维空间的数据。\n",
    "- 缺点：SVM无法很好地处理大规模数据集，需要较长的训练时间，也无法处理包含太多噪声的数据集。SVM模型并没有直接提供概率估计值，而是利用比较耗时的五倍交叉验证估计量，数据量大的话会很耗时。\n",
    "- 对于学生干预系统的数据集，学生的每个特征都是一个维度，学生的信息量也不算巨大 ，我认为SVM非常适合这种多维度的分类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备\n",
    "运行下面的代码单元以初始化三个帮助函数，这三个函数将能够帮你训练和测试你上面所选择的三个监督学习算法。这些函数是：\n",
    "- `train_classifier` - 输入一个分类器和训练集，用数据来训练这个分类器。\n",
    "- `predict_labels` - 输入一个训练好的分类器、特征以及一个目标标签，这个函数将帮你做预测并给出F<sub>1</sub>的值.\n",
    "- `train_predict` - 输入一个分类器以及训练集和测试集，它可以运行`train_clasifier`和`predict_labels`.\n",
    " - 这个函数将分别输出训练集的F<sub>1</sub>值和测试集的F<sub>1</sub>值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' 用训练集训练分类器 '''\n",
    "    \n",
    "    # 开始计时，训练分类器，然后停止计时\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    return end - start\n",
    "  \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' 用训练好的分类器做预测并输出F1值'''\n",
    "    \n",
    "    # 开始计时，作出预测，然后停止计时\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # 输出并返回结果\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "def predict_labels_mine(clf, features, target):\n",
    "    ''' 用训练好的分类器做预测并输出F1值'''\n",
    "    \n",
    "    # 开始计时，作出预测，然后停止计时\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    return f1_score(target.values, y_pred, pos_label='yes'), end - start\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' 用一个分类器训练和预测，并输出F1值 '''\n",
    "      \n",
    "    # 训练一个分类器\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    f1_score_train, train_time = predict_labels_mine(clf, X_train, y_train)\n",
    "    f1_score_test, test_time = predict_labels_mine(clf, X_test, y_test)\n",
    "    \n",
    "    # 输出训练和测试的预测结果\n",
    "    print \"| {:} | {:.4f} | {:.4f} | {:.4f} | {:.4f} |\".format(len(X_train), train_classifier(clf, X_train, y_train), test_time, f1_score_train, f1_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习: 模型评价指标\n",
    "借助于上面定义的函数，你现在需要导入三个你选择的监督学习模型，然后为每一个模型运行`train_predict`函数。请记住，对于每一个模型你需要在不同大小的训练集（100，200和300）上进行训练和测试。所以，你在下面应该会有9个不同的输出（每个模型都有训练集大小不同的三个输出）。在接下来的代码单元中，你将需要实现以下功能：\n",
    "- 引入三个你在上面讨论过的监督式学习算法模型。\n",
    "- 初始化三个模型并将它们存储在`clf_A`， `clf_B` 和 `clf_C`中。\n",
    " - 如果可能对每一个模型都设置一个`random_state`。\n",
    " - **注意:** 这里先使用每一个模型的默认参数，在接下来的部分中你将需要对某一个模型的参数进行调整。\n",
    "- 创建不同大小的训练集用来训练每一个模型。\n",
    " - *不要再混洗和再分割数据！新的训练集要取自`X_train`和`y_train`.*\n",
    "- 对于每一个模型要用不同大小的训练集来训练它，然后在测试集上做测试（总共需要9次训练测试）   \n",
    "**注意:** 在下面的代码单元后面我们提供了三个表用来存储你的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** 分类器 1 - DecisionTreeClassifier **\n",
      "\n",
      "| 训练集大小 | 训练时间 | 预测时间 (测试) | F1值 (训练) | F1值 (测试) |\n",
      "| :----: | :----: | :----: | :----: | :----: |\n",
      "| 100 | 0.0007 | 0.0002 | 1.0000 | 0.7586 |\n",
      "| 200 | 0.0013 | 0.0002 | 1.0000 | 0.7179 |\n",
      "| 300 | 0.0020 | 0.0002 | 1.0000 | 0.6721 |\n",
      "\n",
      "** 分类器 2 - SVC **\n",
      "\n",
      "| 训练集大小 | 训练时间 | 预测时间 (测试) | F1值 (训练) | F1值 (测试) |\n",
      "| :----: | :----: | :----: | :----: | :----: |\n",
      "| 100 | 0.0011 | 0.0007 | 0.8707 | 0.7681 |\n",
      "| 200 | 0.0050 | 0.0019 | 0.8738 | 0.7943 |\n",
      "| 300 | 0.0094 | 0.0017 | 0.8595 | 0.7832 |\n",
      "\n",
      "** 分类器 3 - KNeighborsClassifier **\n",
      "\n",
      "| 训练集大小 | 训练时间 | 预测时间 (测试) | F1值 (训练) | F1值 (测试) |\n",
      "| :----: | :----: | :----: | :----: | :----: |\n",
      "| 100 | 0.0008 | 0.0021 | 0.8182 | 0.6935 |\n",
      "| 200 | 0.0009 | 0.0016 | 0.8264 | 0.7669 |\n",
      "| 300 | 0.0030 | 0.0038 | 0.8761 | 0.7761 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO：从sklearn中引入三个监督学习模型\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# TODO：初始化三个模型\n",
    "clf_A = DecisionTreeClassifier(random_state=5)\n",
    "clf_B = SVC(random_state=5)\n",
    "clf_C = KNeighborsClassifier()\n",
    "\n",
    "clfs = [clf_A, clf_B, clf_C]\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    print \"** 分类器 {} - {} **\".format(i + 1, clfs[i].__class__.__name__)\n",
    "    print ''\n",
    "    print \"| 训练集大小 | 训练时间 | 预测时间 (测试) | F1值 (训练) | F1值 (测试) |\"\n",
    "    print \"| :----: | :----: | :----: | :----: | :----: |\"\n",
    "    for size in [100, 200, 300]: # TODO：设置训练集大小\n",
    "        train_predict(clf, X_train[:size], y_train[:size], X_test, y_test)\n",
    "    print \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果表格\n",
    "编辑下面的表格看看在[Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables)中如何设计一个表格。你需要把上面的结果记录在表格中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 分类器 1 - DecisionTreeClassifier **\n",
    "\n",
    "| 训练集大小 | 训练时间 | 预测时间 (测试) | F1值 (训练) | F1值 (测试) |\n",
    "| :----: | :----: | :----: | :----: | :----: |\n",
    "| 100 | 0.0009 | 0.0003 | 1.0000 | 0.7586 |\n",
    "| 200 | 0.0012 | 0.0002 | 1.0000 | 0.7179 |\n",
    "| 300 | 0.0030 | 0.0006 | 1.0000 | 0.6721 |\n",
    "\n",
    "** 分类器 2 - SVC **\n",
    "\n",
    "| 训练集大小 | 训练时间 | 预测时间 (测试) | F1值 (训练) | F1值 (测试) |\n",
    "| :----: | :----: | :----: | :----: | :----: |\n",
    "| 100 | 0.0016 | 0.0012 | 0.8707 | 0.7681 |\n",
    "| 200 | 0.0040 | 0.0017 | 0.8738 | 0.7943 |\n",
    "| 300 | 0.0070 | 0.0018 | 0.8595 | 0.7832 |\n",
    "\n",
    "** 分类器 3 - KNeighborsClassifier **\n",
    "\n",
    "| 训练集大小 | 训练时间 | 预测时间 (测试) | F1值 (训练) | F1值 (测试) |\n",
    "| :----: | :----: | :----: | :----: | :----: |\n",
    "| 100 | 0.0005 | 0.0012 | 0.8182 | 0.6935 |\n",
    "| 200 | 0.0010 | 0.0017 | 0.8264 | 0.7669 |\n",
    "| 300 | 0.0008 | 0.0029 | 0.8761 | 0.7761 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择最佳模型\n",
    "在最后这一部分中，你将从三个监督学习模型中选择一个用在学生数据上的最佳模型。然后你将在最佳模型上用全部的训练集（`X_train`和`y_train`）运行一个网格搜索算法，在这个过程中，你要至少调整一个参数以提高模型的F<sub>1</sub>值（相比于没有调参的模型的分值有所提高）。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 3 - 选择最佳模型\n",
    "*给予你上面做的实验，用一到两段话，向（学校）监事会解释你将选择哪个模型作为最佳的模型。哪个模型在现有的数据，有限的资源、开支和模型表现综合来看是最好的选择？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **\n",
    "\n",
    "- 通过对Decision Trees， K-Nearest Neighbors ， Support Vector Machines这三种算法模型进行比较。我将会选择Support Vector Machines来作为最佳的模型。\n",
    "- 我认为在成本差距不大的情况下，提高准确度是最重要的。将准确度提高0.01就能在395个学生中多定位到4个学生，这对于学生来说是非常重要的，所以我选择了F1值（测试）最高的算法模型SVM，虽然决策树F1值（训练）很高，但是对于测试集的表现却没有那么好，出现了过拟合，原因应该是没有设置max_depth和min_samples_split，通过设置这两个参数可以对模型进行优化，得到更好的结果，但对于这个问题，决策树仍然不是最好的选择。\n",
    "- SVM的预测时间相比KNN来讲是很经济的，虽然训练时间略长，但我觉得是可接受的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 4 - 用通俗的语言解释模型\n",
    "*用一到两段话，向（学校）监事会用外行也听得懂的话来解释最终模型是如何工作的。你需要解释所选模型的主要特点。例如，这个模型是怎样被训练的，它又是如何做出预测的。避免使用高级的数学或技术术语，不要使用公式或特定的算法名词。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **\n",
    "\n",
    "在这个学生干预系统中，我最终选择了SVM这个算法模型。这是一个非常适合用于分类的模型，尤其适合于多特征的，是或否的简单分类问题。比如我们需要划分的学生是否存在不能毕业的风险。通过SVM这个模型，我们可以根据学生的生活习惯（比如出去玩的次数时间，学习时间），家庭背景（父母的教育情况），经济条件等特征进行分析，从而得知学生能否顺利毕业。\n",
    "\n",
    "SVM的工作原理是这样的，首先我们将往年学生的信息特征以及他们最终是否毕业，把它们标记在一个空间中，他们在原始维度的时候是混乱的，难以划分。因为我们有很多的学生信息的特征，每一个特征都代表一个维度。在SVM的算法模型中有很多神奇的核函数，通过运算，任何在低维中线性不可分的样本集都能找到一个高维特征空间使样本可分。在学生干预系统中，我们使用的核函数是rbf，它帮助我们将能否顺利毕业的学生划分开。\n",
    "\n",
    "比如下图以五星代表顺利毕业的学生，以红点代表没有顺利毕业的学生（当然由于我们有很多的学生信息的特征，实际上是不能展现在一个二维的的平面中的，只作为示例）。\n",
    "\n",
    "SVM可以通过我们输入的学生信息，计算出下图中C这条直线（事实上，C是在高维空间中的一个超平面），这条直线距离顺利毕业和没有顺利毕业的学生都是最远的，所以能够很好的把他们分开，这样我们就完成了对模型的训练。然后当我们输入新的学生信息时，这些学生就会被分到C直线的左上方或者右下方。那么位于C直线左上方的学生我们就可以放心的让他们自主学习，他们基本都是可以顺利毕业的，但是对于C直线右下方的学生我们需要及早的帮助他们以防他们在毕业时遇到障碍。\n",
    "\n",
    "![Mou icon](SVM_4.png)\n",
    "*图片来自于https://www.analyticsvidhya.com/blog/2015/10/understaing-support-vector-machine-example-code/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习: 模型调参\n",
    "细调选择的模型的参数。使用网格搜索（`GridSearchCV`）来至少调整模型的重要参数（至少调整一个），这个参数至少需给出并尝试3个不同的值。你要使用整个训练集来完成这个过程。在接下来的代码单元中，你需要实现以下功能：\n",
    "- 导入 [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) 和 [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- 创建一个对于这个模型你希望调整参数的字典。\n",
    " - 例如: `parameters = {'parameter' : [list of values]}`。\n",
    "- 初始化你选择的分类器，并将其存储在`clf`中。\n",
    "- 使用`make_scorer` 创建F<sub>1</sub>评分函数并将其存储在`f1_scorer`中。\n",
    " - 需正确设定参数`pos_label`的值！\n",
    "- 在分类器`clf`上用`f1_scorer` 作为评价函数运行网格搜索,并将结果存储在`grid_obj`中。\n",
    "- 用训练集(`X_train`, `y_train`)训练grid search object,并将结果存储在`grid_obj`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.0048 seconds.\n",
      "Tuned model has a training F1 score of 0.8560.\n",
      "Made predictions in 0.0018 seconds.\n",
      "Tuned model has a testing F1 score of 0.7917.\n"
     ]
    }
   ],
   "source": [
    "# TODO: 导入 'GridSearchCV' 和 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# TODO：创建你希望调整的参数列表\n",
    "parameters = {'C': [0.9, 1, 5, 10], 'coef0': [0., 1., 2.]}\n",
    "\n",
    "# TODO：初始化分类器\n",
    "clf = SVC()\n",
    "\n",
    "# TODO：用'make_scorer'创建一个f1评分函数\n",
    "f1_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "\n",
    "# TODO：在分类器上使用f1_scorer作为评分函数运行网格搜索\n",
    "grid_obj = GridSearchCV(clf, param_grid=parameters, scoring=f1_scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "# TODO：用训练集训练grid search object来寻找最佳参数\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "# 得到预测的结果\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "# 输出经过调参之后的训练集和测试集的F1值\n",
    "print \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 5 - 最终的 F<sub>1</sub> 值\n",
    "*最终模型的训练和测试的F<sub>1</sub>值是多少？这个值相比于没有调整过参数的模型怎么样？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **\n",
    "\n",
    "Tuned model has a training F1 score of 0.8560 and a testing F1 score of 0.7917.\n",
    "\n",
    "最终模型的训练F1值比没有调整过参数的略低，但是测试的F1值提高了，我认为测试的F1值更重要，所以模型通过调整参数还是得到了优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注意**: 当你写完了所有的代码，并且回答了所有的问题。你就可以把你的 iPython Notebook 导出成 HTML 文件。你可以在菜单栏，这样导出**File -> Download as -> HTML (.html)**把这个 HTML 和这个 iPython notebook 一起做为你的作业提交。  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
